{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 505351,
          "sourceType": "datasetVersion",
          "datasetId": 174469
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ruma13/skin_cancer-tl/blob/main/DenseNet121_Fusion_CBAM_PrePool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "import kagglehub\n",
        "fanconic_skin_cancer_malignant_vs_benign_path = kagglehub.dataset_download('fanconic/skin-cancer-malignant-vs-benign')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "GFL_K59KI8iH"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "import numpy as np\n",
        "from typing import Tuple, Dict, Any\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import models, transforms, datasets\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-11T02:03:38.972904Z",
          "iopub.execute_input": "2025-09-11T02:03:38.974185Z",
          "iopub.status.idle": "2025-09-11T02:03:38.983997Z",
          "shell.execute_reply.started": "2025-09-11T02:03:38.974134Z",
          "shell.execute_reply": "2025-09-11T02:03:38.982295Z"
        },
        "id": "lSN8SmIWI8iJ",
        "outputId": "87689120-8d27-4d29-8707-6063b461e339"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Device: cpu\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA**"
      ],
      "metadata": {
        "id": "4kSO4ANaI8iK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "data_dir = \"/kaggle/input/skin-cancer-malignant-vs-benign\"  # Set your dataset path\n",
        "batch_size = 32\n",
        "num_workers = 4\n",
        "img_size = 224\n",
        "\n",
        "data_transforms = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "    \"val\": transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "    \"test\": transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "full_train_dataset = datasets.ImageFolder(\n",
        "    os.path.join(data_dir, \"train\"),\n",
        "    transform=data_transforms[\"train\"]\n",
        ")\n",
        "\n",
        "val_size = int(0.2 * len(full_train_dataset))\n",
        "train_size = len(full_train_dataset) - val_size\n",
        "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
        "\n",
        "# ==== LOAD TEST DATASET ====\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    os.path.join(data_dir, \"test\"),\n",
        "    transform=data_transforms[\"test\"]\n",
        ")\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                          num_workers=num_workers, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                        num_workers=num_workers, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                         num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "class_names = full_train_dataset.classes\n",
        "num_classes = len(class_names)\n",
        "print(\"Classes:\", class_names)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-11T02:03:38.986816Z",
          "iopub.execute_input": "2025-09-11T02:03:38.987203Z",
          "iopub.status.idle": "2025-09-11T02:03:40.923595Z",
          "shell.execute_reply.started": "2025-09-11T02:03:38.98717Z",
          "shell.execute_reply": "2025-09-11T02:03:40.922687Z"
        },
        "id": "1QSx_jTKI8iL",
        "outputId": "1299438c-215d-4f7d-bfa4-1f0dfe02ab9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Classes: ['benign', 'malignant']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Class Weights And Sampler(Optional)**"
      ],
      "metadata": {
        "id": "Tb893YgRI8iM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize counts\n",
        "counts = np.zeros(num_classes, dtype=np.int64)\n",
        "\n",
        "# full_train_dataset is a Subset of ImageFolder, but here we need the original ImageFolder\n",
        "# full_train_dataset.dataset.imgs gives all (path, label) pairs\n",
        "for _, label in full_train_dataset.imgs:\n",
        "    counts[label] += 1\n",
        "\n",
        "print(\"Class counts:\", counts)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = 1.0 / counts\n",
        "sample_weights = [class_weights[label] for _, label in full_train_dataset.imgs]\n",
        "\n",
        "# Weighted sampler\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "# Create train_loader with sampler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler,\n",
        "                          num_workers=num_workers, pin_memory=True)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-11T02:03:40.924692Z",
          "iopub.execute_input": "2025-09-11T02:03:40.924995Z",
          "iopub.status.idle": "2025-09-11T02:03:40.939125Z",
          "shell.execute_reply.started": "2025-09-11T02:03:40.924972Z",
          "shell.execute_reply": "2025-09-11T02:03:40.937612Z"
        },
        "id": "Hi4-cw4EI8iM",
        "outputId": "e80959ad-2861-440f-9155-9a155461200d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Class counts: [1440 1197]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CBAM: Channel & Spatial Attention**"
      ],
      "metadata": {
        "id": "rzubpmrrI8iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels: int, reduction: int = 16):\n",
        "        super().__init__()\n",
        "        hidden = max(in_channels // reduction, 1)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(in_channels, hidden, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden, in_channels, bias=False)\n",
        "        )\n",
        "        self.pool_avg = nn.AdaptiveAvgPool2d(1)\n",
        "        self.pool_max = nn.AdaptiveMaxPool2d(1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        avg = self.pool_avg(x).view(b, c)\n",
        "        mx  = self.pool_max(x).view(b, c)\n",
        "        attn = self.mlp(avg) + self.mlp(mx)\n",
        "        attn = self.sigmoid(attn).view(b, c, 1, 1)\n",
        "        return x * attn\n",
        "\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size: int = 7):\n",
        "        super().__init__()\n",
        "        padding = kernel_size // 2\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # channel-wise avg and max\n",
        "        avg = torch.mean(x, dim=1, keepdim=True)\n",
        "        mx, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        feat = torch.cat([avg, mx], dim=1)\n",
        "        attn = self.sigmoid(self.conv(feat))\n",
        "        return x * attn\n",
        "\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, in_channels: int, reduction: int = 16, sa_kernel: int = 7):\n",
        "        super().__init__()\n",
        "        self.ca = ChannelAttention(in_channels, reduction)\n",
        "        self.sa = SpatialAttention(sa_kernel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ca(x)\n",
        "        x = self.sa(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-11T02:03:40.941745Z",
          "iopub.execute_input": "2025-09-11T02:03:40.942074Z",
          "iopub.status.idle": "2025-09-11T02:03:40.967975Z",
          "shell.execute_reply.started": "2025-09-11T02:03:40.942049Z",
          "shell.execute_reply": "2025-09-11T02:03:40.966539Z"
        },
        "id": "WBYlj2KVI8iO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model: DenseNet121 Backbone up to layer4 → CBAM → Mid Head → GAP → FC**"
      ],
      "metadata": {
        "id": "b4OoQa-AI8iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "class DenseNetCBAMFusion(nn.Module):\n",
        "    def __init__(self, num_classes: int, unfreeze_last_block: bool = True, mid_channels: int = 1024):\n",
        "        super().__init__()\n",
        "        # Load pretrained DenseNet121\n",
        "        backbone = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        # Take all convolutional features (everything before classifier)\n",
        "        self.stem = backbone.features  # output: (B, 1024, H/32, W/32)\n",
        "        in_ch = 1024\n",
        "\n",
        "        # Freeze all layers by default\n",
        "        for p in self.stem.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # Optionally unfreeze last denseblock + transition for fine-tuning\n",
        "        if unfreeze_last_block:\n",
        "            for p in list(self.stem[-6:].parameters()):  # last denseblock + transition\n",
        "                p.requires_grad = True\n",
        "\n",
        "        # CBAM attention\n",
        "        self.attn = CBAM(in_ch, reduction=16, sa_kernel=7)\n",
        "\n",
        "        # Mid head on feature maps (keeps spatial info)\n",
        "        self.mid = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(mid_channels, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)       # (B, 1024, H/32, W/32)\n",
        "        x = self.attn(x)       # CBAM on maps\n",
        "        x = self.mid(x)        # (B, mid, H/32, W/32)\n",
        "        x = self.pool(x)       # (B, mid, 1, 1)\n",
        "        x = torch.flatten(x, 1)  # (B, mid)\n",
        "        logits = self.fc(x)\n",
        "        return logits\n",
        "\n",
        "# Initialize model\n",
        "model = DenseNetCBAMFusion(num_classes=num_classes, unfreeze_last_block=True, mid_channels=1024).to(device)\n",
        "print(model.__class__.__name__)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-11T02:03:40.969244Z",
          "iopub.execute_input": "2025-09-11T02:03:40.969731Z",
          "iopub.status.idle": "2025-09-11T02:03:41.315348Z",
          "shell.execute_reply.started": "2025-09-11T02:03:40.969703Z",
          "shell.execute_reply": "2025-09-11T02:03:41.314317Z"
        },
        "id": "5RiovEyuI8iP",
        "outputId": "996de653-3314-4bd4-ea6d-4d483e02d38a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "DenseNetCBAMFusion\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer, Loss, and Scheduler**"
      ],
      "metadata": {
        "id": "W8kMZZ4tI8iP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = 15\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-4\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()   # <-- fixed here\n",
        "\n",
        "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=lr, weight_decay=weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-11T02:03:41.316507Z",
          "iopub.execute_input": "2025-09-11T02:03:41.317096Z",
          "iopub.status.idle": "2025-09-11T02:03:41.32575Z",
          "shell.execute_reply.started": "2025-09-11T02:03:41.317061Z",
          "shell.execute_reply": "2025-09-11T02:03:41.32429Z"
        },
        "id": "XrUBPTSWI8iP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Traning And Early Stopping**"
      ],
      "metadata": {
        "id": "M6gRJ0rXI8iQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import numpy as np\n",
        "import copy, time\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Get labels for only the subset used in train_dataset\n",
        "subset_labels = [full_train_dataset.targets[i] for i in train_dataset.indices]\n",
        "\n",
        "# Count samples per class\n",
        "counts = np.bincount(subset_labels, minlength=num_classes)\n",
        "\n",
        "# Compute class weights (inverse frequency)\n",
        "class_weights = 1.0 / counts\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# Assign a weight to each sample in the subset\n",
        "sample_weights = [class_weights[label] for label in subset_labels]\n",
        "\n",
        "# Weighted sampler for training\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "dataloaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\": val_loader,\n",
        "    \"test\": test_loader\n",
        "}\n",
        "\n",
        "print(\"DataLoaders ready!\")\n",
        "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for images, targets in loader:\n",
        "        images, targets = images.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    all_logits, all_targets = [], []\n",
        "    for images, targets in loader:\n",
        "        images, targets = images.to(device), targets.to(device)\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, targets)\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "\n",
        "        all_logits.append(logits.detach().cpu())\n",
        "        all_targets.append(targets.detach().cpu())\n",
        "\n",
        "    avg_loss = running_loss/total\n",
        "    acc = correct/total\n",
        "    all_logits = torch.cat(all_logits)\n",
        "    all_targets = torch.cat(all_targets)\n",
        "    return avg_loss, acc, all_logits, all_targets\n",
        "\n",
        "\n",
        "def macro_metrics(logits, targets, num_classes):\n",
        "    preds = logits.argmax(dim=1).numpy()\n",
        "    y_true = targets.numpy()\n",
        "    f1 = f1_score(y_true, preds, average=\"macro\", zero_division=0)\n",
        "    prec = precision_score(y_true, preds, average=\"macro\", zero_division=0)\n",
        "    rec = recall_score(y_true, preds, average=\"macro\", zero_division=0)\n",
        "\n",
        "    auc = None\n",
        "    try:\n",
        "        if num_classes > 2:\n",
        "            y_bin = np.eye(num_classes)[y_true]\n",
        "            auc = roc_auc_score(y_bin, logits.numpy(), multi_class=\"ovr\")\n",
        "        elif num_classes == 2:\n",
        "            probs = torch.softmax(torch.from_numpy(logits.numpy()), dim=1).numpy()[:, 1]\n",
        "            auc = roc_auc_score(y_true, probs)\n",
        "    except:\n",
        "        auc = None\n",
        "    return f1, prec, rec, auc\n",
        "\n",
        "\n",
        "epochs = 15\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-4\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor if num_classes > 1 else None)\n",
        "\n",
        "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = optim.AdamW(trainable_params, lr=lr, weight_decay=weight_decay)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "best_wts = copy.deepcopy(model.state_dict())\n",
        "best_acc = 0.0\n",
        "patience = 7\n",
        "epochs_no_improve = 0\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    t0 = time.time()\n",
        "    tr_loss, tr_acc = train_one_epoch(model, dataloaders[\"train\"], optimizer, criterion)\n",
        "    val_loss, val_acc, val_logits, val_targets = evaluate(model, dataloaders[\"val\"], criterion)\n",
        "    f1, prec, rec, auc = macro_metrics(val_logits, val_targets, num_classes)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        best_wts = copy.deepcopy(model.state_dict())\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), \"best_cbam_fusion.pt\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "\n",
        "    dt = time.time() - t0\n",
        "    print(f\"Epoch {epoch:02d}/{epochs} | {dt:.1f}s \"\n",
        "          f\"| tr_loss {tr_loss:.4f} acc {tr_acc:.4f} \"\n",
        "          f\"| val_loss {val_loss:.4f} acc {val_acc:.4f} \"\n",
        "          f\"| F1 {f1:.4f} P {prec:.4f} R {rec:.4f} \"\n",
        "          f\"| AUC {auc if auc is not None else 'NA'}\")\n",
        "\n",
        "    if epochs_no_improve >= patience:\n",
        "        print(\"Early stopping.\")\n",
        "        break\n",
        "\n",
        "\n",
        "model.load_state_dict(best_wts)\n",
        "test_loss, test_acc, test_logits, test_targets = evaluate(model, dataloaders[\"test\"], criterion)\n",
        "f1, prec, rec, auc = macro_metrics(test_logits, test_targets, num_classes)\n",
        "print(f\"TEST | loss {test_loss:.4f} acc {test_acc:.4f} \"\n",
        "      f\"| F1 {f1:.4f} P {prec:.4f} R {rec:.4f} \"\n",
        "      f\"| AUC {auc if auc is not None else 'NA'}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-11T02:03:41.327161Z",
          "iopub.execute_input": "2025-09-11T02:03:41.327512Z",
          "iopub.status.idle": "2025-09-11T04:33:02.983579Z",
          "shell.execute_reply.started": "2025-09-11T02:03:41.327487Z",
          "shell.execute_reply": "2025-09-11T04:33:02.981894Z"
        },
        "id": "i2aMEi1VI8iQ",
        "outputId": "62e0da93-2eac-4fdc-d82a-767a23dc7158"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "DataLoaders ready!\nTrain: 2110, Val: 527, Test: 660\nEpoch 01/15 | 581.0s | tr_loss 0.4162 acc 0.8109 | val_loss 0.5295 acc 0.8121 | F1 0.8119 P 0.8232 R 0.8291 | AUC 0.8975273911755997\nEpoch 02/15 | 584.2s | tr_loss 0.2907 acc 0.8687 | val_loss 0.4668 acc 0.8254 | F1 0.8251 P 0.8339 R 0.8411 | AUC 0.921587207580693\nEpoch 03/15 | 603.2s | tr_loss 0.2531 acc 0.8844 | val_loss 0.3322 acc 0.8596 | F1 0.8571 P 0.8549 R 0.8614 | AUC 0.9412644358898431\nEpoch 04/15 | 578.8s | tr_loss 0.2365 acc 0.8953 | val_loss 0.4149 acc 0.8482 | F1 0.8479 P 0.8557 R 0.8639 | AUC 0.949185667752443\nEpoch 05/15 | 592.5s | tr_loss 0.2008 acc 0.9057 | val_loss 0.3502 acc 0.8767 | F1 0.8751 P 0.8732 R 0.8825 | AUC 0.9493633402428191\nEpoch 06/15 | 606.4s | tr_loss 0.1842 acc 0.9199 | val_loss 0.2721 acc 0.8767 | F1 0.8726 P 0.8746 R 0.8710 | AUC 0.9568700029612083\nEpoch 07/15 | 596.8s | tr_loss 0.1655 acc 0.9294 | val_loss 0.4248 acc 0.8539 | F1 0.8530 P 0.8550 R 0.8649 | AUC 0.9430929819366303\nEpoch 08/15 | 580.7s | tr_loss 0.1486 acc 0.9379 | val_loss 0.3450 acc 0.8634 | F1 0.8552 P 0.8736 R 0.8473 | AUC 0.9514509920047379\nEpoch 09/15 | 613.9s | tr_loss 0.1519 acc 0.9422 | val_loss 0.3172 acc 0.8805 | F1 0.8732 P 0.8932 R 0.8645 | AUC 0.9625259105715132\nEpoch 10/15 | 583.6s | tr_loss 0.0905 acc 0.9640 | val_loss 0.3205 acc 0.8767 | F1 0.8730 P 0.8737 R 0.8722 | AUC 0.9592981936630145\nEpoch 11/15 | 588.7s | tr_loss 0.0717 acc 0.9749 | val_loss 0.3050 acc 0.9051 | F1 0.9027 P 0.9018 R 0.9038 | AUC 0.9627035830618893\nEpoch 12/15 | 602.6s | tr_loss 0.0650 acc 0.9739 | val_loss 0.2923 acc 0.9108 | F1 0.9079 P 0.9101 R 0.9061 | AUC 0.9665975718092982\nEpoch 13/15 | 588.5s | tr_loss 0.0602 acc 0.9777 | val_loss 0.2534 acc 0.9298 | F1 0.9278 P 0.9281 R 0.9275 | AUC 0.9733343204027243\nEpoch 14/15 | 592.0s | tr_loss 0.0370 acc 0.9863 | val_loss 0.2487 acc 0.9108 | F1 0.9086 P 0.9075 R 0.9099 | AUC 0.9736452472608825\nEpoch 15/15 | 594.6s | tr_loss 0.0296 acc 0.9924 | val_loss 0.2819 acc 0.8975 | F1 0.8942 P 0.8960 R 0.8927 | AUC 0.9699437370447144\nTEST | loss 0.3093 acc 0.9167 | F1 0.9160 P 0.9157 R 0.9164 | AUC 0.9702222222222222\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**"
      ],
      "metadata": {
        "id": "sZbLDy9eI8iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_confusion_matrix(logits, targets, classes):\n",
        "    preds = logits.argmax(dim=1).numpy()\n",
        "    y_true = targets.numpy()\n",
        "    cm = confusion_matrix(y_true, preds, labels=list(range(len(classes))))\n",
        "\n",
        "    fig = plt.figure(figsize=(6, 5))\n",
        "    plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45, ha='right')\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "\n",
        "    # Add counts\n",
        "    thresh = cm.max() / 2.0 if cm.max() > 0 else 0.5\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(test_logits, test_targets, class_names)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-11T04:33:03.407412Z",
          "iopub.execute_input": "2025-09-11T04:33:03.407706Z",
          "iopub.status.idle": "2025-09-11T04:33:03.538651Z",
          "shell.execute_reply.started": "2025-09-11T04:33:03.407684Z",
          "shell.execute_reply": "2025-09-11T04:33:03.537634Z"
        },
        "id": "V1cKgKxxI8iR",
        "outputId": "52ec58bc-c952-4b54-b626-31d01415fb21"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 600x500 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc, test_logits, test_targets = evaluate(model, dataloaders[\"test\"], criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-11T04:39:43.458079Z",
          "iopub.execute_input": "2025-09-11T04:39:43.45853Z",
          "iopub.status.idle": "2025-09-11T04:40:55.862745Z",
          "shell.execute_reply.started": "2025-09-11T04:39:43.4585Z",
          "shell.execute_reply": "2025-09-11T04:40:55.861383Z"
        },
        "id": "6XL3iWKdI8iR",
        "outputId": "ae7d0c45-c118-4fef-d1e7-858f39e82c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Test Loss: 0.3093\nTest Accuracy: 0.9167\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}